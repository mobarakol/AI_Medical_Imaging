{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/AI_Medical_Imaging/blob/main/Active_Learning_Training_ReseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWVbrV1R3G3L"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1Oms9X0Vpid_kN8jiSgz-3MhRA5BcmivE'\n",
        "gdown.download(url,'braintumor.zip',quiet=True)\n",
        "!unzip -q braintumor.zip -d braintumor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "from collections import Counter\n",
        "\n",
        "# Set a fixed seed for reproducibility\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                std=[0.229, 0.224, 0.225])\n",
        "\n",
        "dataset_ = datasets.ImageFolder(root='/content/braintumor/Training', transform=transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "]))\n",
        "\n",
        "# Define split ratios\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.2\n",
        "\n",
        "# Calculate lengths for each split\n",
        "total_size = len(dataset_)\n",
        "train_size = int(total_size * train_ratio)\n",
        "val_size = total_size - train_size\n",
        "\n",
        "# Perform the split\n",
        "train_split, val_split = torch.utils.data.random_split(dataset_, [train_size, val_size])\n",
        "\n",
        "# Print split information\n",
        "print(f\"Total samples: {len(dataset_)}\")\n",
        "print(f\"Training samples: {len(train_split)}\")\n",
        "print(f\"Validation samples: {len(val_split)}\")\n",
        "\n",
        "# Mapping of class indices to class names\n",
        "class_to_idx = dataset_.class_to_idx\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "\n",
        "# Extract labels from train_split\n",
        "train_labels = [dataset_.samples[idx][1] for idx in train_split.indices]\n",
        "\n",
        "# Count class frequencies\n",
        "class_counts = Counter(train_labels)\n",
        "\n",
        "# Map frequencies back to class names\n",
        "class_frequencies = {idx_to_class[idx]: count for idx, count in class_counts.items()}\n",
        "\n",
        "# Print class frequencies\n",
        "print(\"\\nClass frequencies in train_split:\")\n",
        "for class_name, count in class_frequencies.items():\n",
        "    print(f\"Class '{class_name}': {count} images\")\n",
        "\n",
        "\n",
        "# Extract labels from val_split\n",
        "valid_labels = [dataset_.samples[idx][1] for idx in val_split.indices]\n",
        "\n",
        "# Count class frequencies\n",
        "class_counts = Counter(valid_labels)\n",
        "\n",
        "# Map frequencies back to class names\n",
        "class_frequencies = {idx_to_class[idx]: count for idx, count in class_counts.items()}\n",
        "\n",
        "# Print class frequencies\n",
        "print(\"\\nClass frequencies in val_split:\")\n",
        "for class_name, count in class_frequencies.items():\n",
        "    print(f\"Class '{class_name}': {count} images\")"
      ],
      "metadata": {
        "id": "Ie4zrvXq3mnx",
        "outputId": "0e0d3201-9b1f-463e-a6c1-fd1743b639af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 5712\n",
            "Training samples: 4569\n",
            "Validation samples: 1143\n",
            "\n",
            "Class frequencies in train_split:\n",
            "Class 'glioma': 1051 images\n",
            "Class 'notumor': 1276 images\n",
            "Class 'pituitary': 1166 images\n",
            "Class 'meningioma': 1076 images\n",
            "\n",
            "Class frequencies in val_split:\n",
            "Class 'meningioma': 263 images\n",
            "Class 'glioma': 270 images\n",
            "Class 'pituitary': 291 images\n",
            "Class 'notumor': 319 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "def get_arguments():\n",
        "    parser = argparse.ArgumentParser(description='CIFAR-10H Training')\n",
        "    parser.add_argument('--lr', default=1e-4, type=float, help='learning rate')\n",
        "    parser.add_argument('--lr_schedule', default=0, type=int, help='lr scheduler')\n",
        "    parser.add_argument('--batch_size', default=128, type=int, help='batch size')\n",
        "    parser.add_argument('--test_batch_size', default=256, type=int, help='batch size')\n",
        "    parser.add_argument('--num_epoch', default=10, type=int, help='epoch number')\n",
        "    parser.add_argument('--num_classes', type=int, default=4, help='number classes')\n",
        "    if 'ipykernel' in sys.modules:\n",
        "        args = parser.parse_args([])\n",
        "    else:\n",
        "        args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "def train(model, trainloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def test(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = get_arguments()\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    trainloader = DataLoader(train_split, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
        "    testloader = DataLoader(val_split, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
        "    print('Training on:', device, 'train sample size:', len(train_split), 'test sample size:', len(val_split))\n",
        "\n",
        "    model = models.resnet34(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, args.num_classes)\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr, betas=(0.9, 0.999), weight_decay=0.1)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_epoch, best_acc = 0.0, 0\n",
        "    for epoch in range(args.num_epoch):\n",
        "        train(model, trainloader, criterion, optimizer)\n",
        "        accuracy = test(model, testloader)\n",
        "        if accuracy > best_acc:\n",
        "            patience = 0\n",
        "            best_acc = accuracy\n",
        "            best_epoch = epoch\n",
        "            torch.save(model.state_dict(), 'best_model_{}.pth.tar'.format(epoch))\n",
        "        print('epoch: {}  acc: {:.4f}  best epoch: {}  best acc: {:.4f}'.format(\n",
        "                epoch, accuracy, best_epoch, best_acc, optimizer.param_groups[0]['lr']))\n"
      ],
      "metadata": {
        "id": "s_g08Z5Q4HcZ",
        "outputId": "d388a991-dad6-47f0-9d61-88a78deb3413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on: cuda train sample size: 4569 test sample size: 1143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BaBLA0Yb6P3N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}